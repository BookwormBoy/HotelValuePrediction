{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 81 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       1200 non-null   int64  \n",
      " 1   PropertyClass            1200 non-null   int64  \n",
      " 2   ZoningCategory           1200 non-null   object \n",
      " 3   RoadAccessLength         977 non-null    float64\n",
      " 4   LandArea                 1200 non-null   int64  \n",
      " 5   RoadType                 1200 non-null   object \n",
      " 6   ServiceLaneType          75 non-null     object \n",
      " 7   PlotShape                1200 non-null   object \n",
      " 8   LandElevation            1200 non-null   object \n",
      " 9   UtilityAccess            1200 non-null   object \n",
      " 10  PlotConfiguration        1200 non-null   object \n",
      " 11  LandSlope                1200 non-null   object \n",
      " 12  District                 1200 non-null   object \n",
      " 13  NearbyTransport1         1200 non-null   object \n",
      " 14  NearbyTransport2         1200 non-null   object \n",
      " 15  PropertyType             1200 non-null   object \n",
      " 16  HotelStyle               1200 non-null   object \n",
      " 17  OverallQuality           1200 non-null   int64  \n",
      " 18  OverallCondition         1200 non-null   int64  \n",
      " 19  ConstructionYear         1200 non-null   int64  \n",
      " 20  RenovationYear           1200 non-null   int64  \n",
      " 21  RoofDesign               1200 non-null   object \n",
      " 22  RoofMaterial             1200 non-null   object \n",
      " 23  ExteriorPrimary          1200 non-null   object \n",
      " 24  ExteriorSecondary        1200 non-null   object \n",
      " 25  FacadeType               498 non-null    object \n",
      " 26  FacadeArea               1193 non-null   float64\n",
      " 27  ExteriorQuality          1200 non-null   object \n",
      " 28  ExteriorCondition        1200 non-null   object \n",
      " 29  FoundationType           1200 non-null   object \n",
      " 30  BasementHeight           1171 non-null   object \n",
      " 31  BasementCondition        1171 non-null   object \n",
      " 32  BasementExposure         1170 non-null   object \n",
      " 33  BasementFacilityType1    1171 non-null   object \n",
      " 34  BasementFacilitySF1      1200 non-null   int64  \n",
      " 35  BasementFacilityType2    1171 non-null   object \n",
      " 36  BasementFacilitySF2      1200 non-null   int64  \n",
      " 37  BasementUnfinishedSF     1200 non-null   int64  \n",
      " 38  BasementTotalSF          1200 non-null   int64  \n",
      " 39  HeatingType              1200 non-null   object \n",
      " 40  HeatingQuality           1200 non-null   object \n",
      " 41  CentralAC                1200 non-null   object \n",
      " 42  ElectricalSystem         1199 non-null   object \n",
      " 43  GroundFloorArea          1200 non-null   int64  \n",
      " 44  UpperFloorArea           1200 non-null   int64  \n",
      " 45  LowQualityArea           1200 non-null   int64  \n",
      " 46  UsableArea               1200 non-null   int64  \n",
      " 47  BasementFullBaths        1200 non-null   int64  \n",
      " 48  BasementHalfBaths        1200 non-null   int64  \n",
      " 49  FullBaths                1200 non-null   int64  \n",
      " 50  HalfBaths                1200 non-null   int64  \n",
      " 51  GuestRooms               1200 non-null   int64  \n",
      " 52  Kitchens                 1200 non-null   int64  \n",
      " 53  KitchenQuality           1200 non-null   object \n",
      " 54  TotalRooms               1200 non-null   int64  \n",
      " 55  PropertyFunctionality    1200 non-null   object \n",
      " 56  Lounges                  1200 non-null   int64  \n",
      " 57  LoungeQuality            640 non-null    object \n",
      " 58  ParkingType              1135 non-null   object \n",
      " 59  ParkingConstructionYear  1135 non-null   float64\n",
      " 60  ParkingFinish            1135 non-null   object \n",
      " 61  ParkingCapacity          1200 non-null   int64  \n",
      " 62  ParkingArea              1200 non-null   int64  \n",
      " 63  ParkingQuality           1135 non-null   object \n",
      " 64  ParkingCondition         1135 non-null   object \n",
      " 65  DrivewayType             1200 non-null   object \n",
      " 66  TerraceArea              1200 non-null   int64  \n",
      " 67  OpenVerandaArea          1200 non-null   int64  \n",
      " 68  EnclosedVerandaArea      1200 non-null   int64  \n",
      " 69  SeasonalPorchArea        1200 non-null   int64  \n",
      " 70  ScreenPorchArea          1200 non-null   int64  \n",
      " 71  SwimmingPoolArea         1200 non-null   int64  \n",
      " 72  PoolQuality              6 non-null      object \n",
      " 73  BoundaryFence            237 non-null    object \n",
      " 74  ExtraFacility            46 non-null     object \n",
      " 75  ExtraFacilityValue       1200 non-null   int64  \n",
      " 76  MonthSold                1200 non-null   int64  \n",
      " 77  YearSold                 1200 non-null   int64  \n",
      " 78  DealType                 1200 non-null   object \n",
      " 79  DealCondition            1200 non-null   object \n",
      " 80  HotelValue               1200 non-null   float64\n",
      "dtypes: float64(4), int64(34), object(43)\n",
      "memory usage: 759.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load and examine basic structure\n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original maximum value: 745000.0\n",
      "Maximum value after capping: 616628.6670000067\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.hist(train_df['HotelValue'], bins=50)\n",
    "percentile_threshold = train_df['HotelValue'].quantile(0.999)\n",
    "print(\"Original maximum value:\", train_df['HotelValue'].max())\n",
    "# Cap the values at the 99.9th percentile\n",
    "train_df['HotelValue'] = train_df['HotelValue'].clip(upper=percentile_threshold)\n",
    "print(\"Maximum value after capping:\", train_df['HotelValue'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data preparation pipeline...\n",
      "Target variable 'HotelValue' separated and log-transformed (y_log).\n",
      "Initial train data shape: (1200, 80)\n",
      "Initial test data shape: (260, 80)\n",
      "Combined dataset shape for processing: (1460, 80)\n",
      "Filled missing values based on the predefined mapping.\n",
      "Applied all specified ordinal mappings.\n",
      "Dynamically identified 36 numerical features.\n",
      "Applied one-hot encoding. New feature count: 227\n",
      "Final training features shape (X): (1200, 226)\n",
      "Final test features shape (X_test): (260, 226)\n",
      "Identified 56 total features to be scaled.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing data preparation pipeline...\")\n",
    "\n",
    "# Configuration for handling missing values\n",
    "# Defines specific replacements for columns with known 'NA' meanings\n",
    "MISSING_VALUE_MAP = {\n",
    "    'RoadAccessLength': 0, 'ServiceLaneType': 'NoServiceLane', 'FacadeType': 'NoFacade',\n",
    "    'FacadeArea': 0, 'BasementHeight': 'NoBasement', 'BasementCondition': 'NoBasement',\n",
    "    'BasementExposure': 'NoBasementExposure', 'BasementFacilityType1': 'NoBasement',\n",
    "    'BasementFacilityType2': 'NoBasement', 'ElectricalSystem': 'NoElectricalSystem',\n",
    "    'LoungeQuality': 'NoLounge', 'ParkingType': 'NoParking',\n",
    "    'ParkingConstructionYear': 0, 'ParkingFinish': 'NoParking',\n",
    "    'ParkingQuality': 'NoParking', 'ParkingCondition': 'NoParking',\n",
    "    'PoolQuality': 'NoPool', 'BoundaryFence': 'NoBoundaryFence',\n",
    "    'ExtraFacility': 'NoExtraFacility'\n",
    "}\n",
    "\n",
    "# --- Ordinal Mappings ---\n",
    "# Generic scale for quality-related features (e.g., Ex, Gd, TA, Fa, Po)\n",
    "GENERIC_QUALITY_SCALE = {\n",
    "    'NoBasement': 0, 'NoLounge': 0, 'NoParking': 0, 'NoPool': 0,\n",
    "    'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5\n",
    "}\n",
    "\n",
    "# Specific scales for other categorical features that have an inherent order\n",
    "BSMT_EXPOSURE_SCALE = {'NoBasementExposure': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
    "BSMT_FACILITY_SCALE = {\n",
    "    'NoBasement': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6\n",
    "}\n",
    "PLOT_SHAPE_SCALE = {'Reg': 3, 'IR1': 2, 'IR2': 1, 'IR3': 0}\n",
    "LAND_SLOPE_SCALE = {'Gtl': 2, 'Mod': 1, 'Sev': 0}\n",
    "FUNCTIONALITY_SCALE = {'Sev': 0, 'Maj2': 1, 'Maj1': 2, 'Mod': 3, 'Min2': 4, 'Min1': 5, 'Typ': 6}\n",
    "PARKING_FINISH_SCALE = {'NoParking': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "DRIVEWAY_SCALE = {'N': 0, 'P': 1, 'Y': 2}\n",
    "FENCE_SCALE = {'NoBoundaryFence': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
    "UTILITY_SCALE = {'NoSeWa': 0, 'AllPub': 1}\n",
    "\n",
    "# --- Column Groupings ---\n",
    "# List of columns that use the GENERIC_QUALITY_SCALE\n",
    "QUALITY_COLS_TO_MAP = [\n",
    "    'ExteriorQuality', 'ExteriorCondition', 'BasementHeight', 'BasementCondition',\n",
    "    'HeatingQuality', 'KitchenQuality', 'LoungeQuality', 'ParkingQuality', 'ParkingCondition',\n",
    "    'PoolQuality'\n",
    "]\n",
    "\n",
    "# Set of all columns that will be ordinally encoded\n",
    "ORDINAL_FEATURES_SET = set(QUALITY_COLS_TO_MAP + [\n",
    "    'BasementExposure', 'BasementFacilityType1', 'BasementFacilityType2', \n",
    "    'PlotShape', 'LandSlope', 'PropertyFunctionality', 'ParkingFinish', \n",
    "    'DrivewayType', 'BoundaryFence', 'UtilityAccess'\n",
    "])\n",
    "\n",
    "# Set of columns that will be one-hot encoded (nominal features)\n",
    "NOMINAL_FEATURES_SET = set([\n",
    "    'ZoningCategory', 'RoadType', 'ServiceLaneType', 'LandElevation', 'PlotConfiguration',\n",
    "    'District', 'NearbyTransport1', 'NearbyTransport2', 'PropertyType', 'HotelStyle',\n",
    "    'RoofDesign', 'RoofMaterial', 'ExteriorPrimary', 'ExteriorSecondary', 'FacadeType',\n",
    "    'FoundationType', 'HeatingType', 'CentralAC', 'ElectricalSystem', 'ParkingType',\n",
    "    'ExtraFacility', 'DealType', 'DealCondition'\n",
    "])\n",
    "\n",
    "# === 1. Isolate Target Variable ===\n",
    "# Separate the target 'HotelValue' and apply log-transform to handle skewness\n",
    "y = train_df['HotelValue']\n",
    "y_log = np.log1p(y)\n",
    "train_df = train_df.drop(columns='HotelValue')\n",
    "print(\"Target variable 'HotelValue' separated and log-transformed (y_log).\")\n",
    "\n",
    "# === 2. Combine Datasets for Processing ===\n",
    "# Concatenate train and test data for consistent preprocessing\n",
    "print(f\"Initial train data shape: {train_df.shape}\")\n",
    "print(f\"Initial test data shape: {test_df.shape}\")\n",
    "full_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "print(f\"Combined dataset shape for processing: {full_df.shape}\")\n",
    "\n",
    "# === 3. Impute Missing Values ===\n",
    "full_df.fillna(MISSING_VALUE_MAP, inplace=True)\n",
    "print(\"Filled missing values based on the predefined mapping.\")\n",
    "\n",
    "# === 4. Apply Ordinal Encoding ===\n",
    "# Map string categories to numerical values based on defined scales\n",
    "for col in QUALITY_COLS_TO_MAP:\n",
    "    full_df[col] = full_df[col].map(GENERIC_QUALITY_SCALE)\n",
    "    \n",
    "full_df['BasementExposure'] = full_df['BasementExposure'].map(BSMT_EXPOSURE_SCALE)\n",
    "full_df['BasementFacilityType1'] = full_df['BasementFacilityType1'].map(BSMT_FACILITY_SCALE)\n",
    "full_df['BasementFacilityType2'] = full_df['BasementFacilityType2'].map(BSMT_FACILITY_SCALE)\n",
    "full_df['PlotShape'] = full_df['PlotShape'].map(PLOT_SHAPE_SCALE)\n",
    "full_df['LandSlope'] = full_df['LandSlope'].map(LAND_SLOPE_SCALE)\n",
    "full_df['PropertyFunctionality'] = full_df['PropertyFunctionality'].map(FUNCTIONALITY_SCALE)\n",
    "full_df['ParkingFinish'] = full_df['ParkingFinish'].map(PARKING_FINISH_SCALE)\n",
    "full_df['DrivewayType'] = full_df['DrivewayType'].map(DRIVEWAY_SCALE)\n",
    "full_df['BoundaryFence'] = full_df['BoundaryFence'].map(FENCE_SCALE)\n",
    "full_df['UtilityAccess'] = full_df['UtilityAccess'].map(UTILITY_SCALE)\n",
    "print(\"Applied all specified ordinal mappings.\")\n",
    "\n",
    "# === 5. Identify Remaining Numerical Features ===\n",
    "# Dynamically find columns that weren't specified as ordinal or nominal\n",
    "original_feature_set = set(train_df.columns)\n",
    "NUMERIC_FEATURES_SET = original_feature_set - ORDINAL_FEATURES_SET - NOMINAL_FEATURES_SET - {'Id'}\n",
    "print(f\"Dynamically identified {len(NUMERIC_FEATURES_SET)} numerical features.\")\n",
    "# print(f\"Identified numerical features: {NUMERIC_FEATURES_SET}\") # Uncomment for debugging\n",
    "\n",
    "# === 6. Apply One-Hot Encoding ===\n",
    "# Convert nominal categorical features into dummy variables\n",
    "full_df = pd.get_dummies(full_df, columns=list(NOMINAL_FEATURES_SET), dummy_na=False)\n",
    "print(f\"Applied one-hot encoding. New feature count: {full_df.shape[1]}\")\n",
    "\n",
    "# === 7. Split Back to Train/Test ===\n",
    "# Separate the processed data back into training and testing sets\n",
    "X = full_df.iloc[:len(train_df)]\n",
    "X_test = full_df.iloc[len(train_df):]\n",
    "\n",
    "# Drop the ID column as it's an identifier, not a feature\n",
    "X = X.drop(columns='Id')\n",
    "X_test = X_test.drop(columns='Id')\n",
    "\n",
    "print(f\"Final training features shape (X): {X.shape}\")\n",
    "print(f\"Final test features shape (X_test): {X_test.shape}\")\n",
    "\n",
    "# === 8. Define Features for Scaling ===\n",
    "# We will scale all original numerical features + the new ordinal features\n",
    "cols_to_scale = list(NUMERIC_FEATURES_SET) + list(ORDINAL_FEATURES_SET)\n",
    "# Verify columns exist (this is good practice)\n",
    "cols_to_scale = [col for col in cols_to_scale if col in X.columns]\n",
    "print(f\"Identified {len(cols_to_scale)} total features to be scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Engineered Features + PCA pipeline...\n",
      "Created 9 new engineered features.\n",
      "Combined dataset shape: (1200, 235)\n",
      "Scaling combined dataset...\n",
      "Applying PCA to combined dataset (n_components=0.99)...\n",
      "Original features: 235\n",
      "PCA-reduced features: 171\n",
      "\n",
      "=== Training Linear Regression on Engineered PCA components ===\n",
      "\n",
      "Test Predictions (Engineered + PCA):\n",
      "Sample: [147372.47473656 331867.01849212 103597.53798322 166763.80803247\n",
      " 307203.21882291]\n",
      "Min: $47680.21\n",
      "Max: $774456.36\n",
      "Mean: $176872.74\n",
      "\n",
      " Submission saved as 'submission_linear_regression_eng_pca.csv'\n",
      "     Id     HotelValue\n",
      "0   893  147372.474737\n",
      "1  1106  331867.018492\n",
      "2   414  103597.537983\n",
      "3   523  166763.808032\n",
      "4  1037  307203.218823\n",
      "5   615   78155.220919\n",
      "6   219  245776.322295\n",
      "7  1161  143137.741076\n",
      "8   650   74863.431014\n",
      "9   888  149476.326423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Data is already prepared (X, y_log, X_test) ---\n",
    "# X and X_test contain ALL features (ordinal, OHE, etc.)\n",
    "# 'cols_to_scale' is defined and lists all non-OHE columns\n",
    "\n",
    "\n",
    "test_ids = test_df['Id'].copy()\n",
    "\n",
    "print(\"Starting Engineered Features + PCA pipeline...\")\n",
    "\n",
    "# --- Create Engineered Features ---\n",
    "# Create new DataFrames to hold our new features\n",
    "X_train_eng = pd.DataFrame(index=X.index)\n",
    "X_test_eng = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Polynomials (quality is exponential)\n",
    "X_train_eng['OverallQual_sq'] = X['OverallQuality']**2\n",
    "X_test_eng['OverallQual_sq'] = X_test['OverallQuality']**2\n",
    "\n",
    "X_train_eng['OverallQual_cub'] = X['OverallQuality']**3\n",
    "X_test_eng['OverallQual_cub'] = X_test['OverallQuality']**3\n",
    "\n",
    "# Total Sizes\n",
    "X_train_eng['TotalSF'] = X['BasementTotalSF'] + X['GroundFloorArea'] + X['UpperFloorArea']\n",
    "X_test_eng['TotalSF'] = X_test['BasementTotalSF'] + X_test['GroundFloorArea'] + X_test['UpperFloorArea']\n",
    "\n",
    "X_train_eng['TotalBaths'] = X['FullBaths'] + (0.5 * X['HalfBaths']) + X['BasementFullBaths']\n",
    "X_test_eng['TotalBaths'] = X_test['FullBaths'] + (0.5 * X_test['HalfBaths']) + X_test['BasementFullBaths']\n",
    "\n",
    "X_train_eng['TotalPorchSF'] = X['TerraceArea'] + X['OpenVerandaArea'] + X['EnclosedVerandaArea']\n",
    "X_test_eng['TotalPorchSF'] = X_test['TerraceArea'] + X_test['OpenVerandaArea'] + X_test['EnclosedVerandaArea']\n",
    "\n",
    "# Age\n",
    "X_train_eng['HouseAge'] = X['YearSold'] - X['ConstructionYear']\n",
    "X_test_eng['HouseAge'] = X_test['YearSold'] - X_test['ConstructionYear']\n",
    "\n",
    "X_train_eng['AgeSinceRemod'] = X['YearSold'] - X['RenovationYear']\n",
    "X_test_eng['AgeSinceRemod'] = X_test['YearSold'] - X_test['RenovationYear']\n",
    "\n",
    "# Interactions\n",
    "X_train_eng['Qual_x_TotalSF'] = X['OverallQuality'] * X_train_eng['TotalSF']\n",
    "X_test_eng['Qual_x_TotalSF'] = X_test['OverallQuality'] * X_test_eng['TotalSF']\n",
    "\n",
    "X_train_eng['Qual_x_HouseAge'] = X['OverallQuality'] * X_train_eng['HouseAge']\n",
    "X_test_eng['Qual_x_HouseAge'] = X_test['OverallQuality'] * X_test_eng['HouseAge']\n",
    "\n",
    "print(f\"Created {X_train_eng.shape[1]} new engineered features.\")\n",
    "\n",
    "# --- Combine Engineered + Original Features ---\n",
    "# This joins our new features with ALL the original features from your config cell\n",
    "X_train_combined = X.join(X_train_eng)\n",
    "X_test_combined = X_test.join(X_test_eng)\n",
    "\n",
    "print(f\"Combined dataset shape: {X_train_combined.shape}\")\n",
    "\n",
    "# --- Scale the ENTIRE Combined Dataset ---\n",
    "# We must scale everything before PCA\n",
    "print(\"Scaling combined dataset...\")\n",
    "scaler_combined = StandardScaler()\n",
    "X_train_scaled = scaler_combined.fit_transform(X_train_combined)\n",
    "X_test_scaled = scaler_combined.transform(X_test_combined)\n",
    "\n",
    "# --- Apply PCA ---\n",
    "# We use a high variance threshold to keep as much info as possible\n",
    "pca = PCA(n_components=0.99, random_state=42)\n",
    "print(\"Applying PCA to combined dataset (n_components=0.99)...\")\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Original features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"PCA-reduced features: {X_train_pca.shape[1]}\")\n",
    "\n",
    "# --- Train Linear Regression on PCA components ---\n",
    "print(\"\\n=== Training Linear Regression on Engineered PCA components ===\")\n",
    "lr_model_final = LinearRegression()\n",
    "lr_model_final.fit(X_train_pca, y_log) # Fit on the new PCA data\n",
    "\n",
    "# Make test predictions\n",
    "preds = lr_model_final.predict(X_test_pca) \n",
    "y_test_pred_actual = np.expm1(preds) # This will be stable\n",
    "\n",
    "print(f\"\\nTest Predictions (Engineered + PCA):\")\n",
    "print(f\"Sample: {y_test_pred_actual[:5]}\")\n",
    "print(f\"Min: ${y_test_pred_actual.min():.2f}\")\n",
    "print(f\"Max: ${y_test_pred_actual.max():.2f}\")\n",
    "print(f\"Mean: ${y_test_pred_actual.mean():.2f}\")\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'HotelValue': y_test_pred_actual\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_linear_regression_eng_pca.csv', index=False)\n",
    "print(\"\\n Submission saved as 'submission_linear_regression_eng_pca.csv'\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Ridge Regression ===\n",
      "\n",
      " Ridge submission saved as 'submission_ridge.csv'\n",
      "     Id     HotelValue\n",
      "0   893  147367.028569\n",
      "1  1106  331799.577907\n",
      "2   414  103591.459251\n",
      "3   523  166733.233566\n",
      "4  1037  307227.589608\n",
      "\n",
      "=== Training Lasso Regression ===\n",
      "\n",
      " Lasso submission saved as 'submission_lasso.csv'\n",
      "     Id     HotelValue\n",
      "0   893  146870.560745\n",
      "1  1106  329762.087313\n",
      "2   414  102899.883547\n",
      "3   523  166344.535955\n",
      "4  1037  309218.351396\n",
      "\n",
      "=== Training Elastic Net Regression ===\n",
      "\n",
      " Elastic Net submission saved as 'submission_elastic_net.csv'\n",
      "     Id     HotelValue\n",
      "0   893  146867.809320\n",
      "1  1106  329725.512106\n",
      "2   414  102897.286898\n",
      "3   523  166325.400169\n",
      "4  1037  309229.990777\n",
      "\n",
      "=== Tuning Ridge Alpha ===\n",
      "Best Ridge Alpha: 100.0\n",
      "Best Ridge RMSE (negated): -0.1449726879752317\n",
      "\n",
      " Best Ridge submission saved as 'submission_best_ridge.csv'\n",
      "     Id     HotelValue\n",
      "0   893  146751.141903\n",
      "1  1106  326664.541323\n",
      "2   414  103240.988696\n",
      "3   523  164224.016203\n",
      "4  1037  309043.798121\n",
      "\n",
      "=== Tuning Lasso Alpha ===\n",
      "Best Lasso Alpha: 0.0033932217718953264\n",
      "Best Lasso RMSE (negated): -0.1477009340930391\n",
      "\n",
      " Best Lasso submission saved as 'submission_best_lasso.csv'\n",
      "     Id     HotelValue\n",
      "0   893  145688.147044\n",
      "1  1106  317672.566908\n",
      "2   414  100512.563164\n",
      "3   523  157975.277688\n",
      "4  1037  315558.300891\n",
      "\n",
      "=== Tuning ElasticNet Alpha and L1 Ratio ===\n",
      "Best ElasticNet Params: {'alpha': 0.0307029062975785, 'l1_ratio': 0.1}\n",
      "Best ElasticNet RMSE (negated): -0.14669784029324753\n",
      "\n",
      " Best ElasticNet submission saved as 'submission_best_enet.csv'\n",
      "     Id     HotelValue\n",
      "0   893  145438.604862\n",
      "1  1106  318254.329550\n",
      "2   414  100799.628676\n",
      "3   523  158453.079102\n",
      "4  1037  315166.244475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Ridge Regression ---\n",
    "print(\"\\n=== Training Ridge Regression ===\")\n",
    "ridge = Ridge(alpha=1.0) # Start with a default alpha\n",
    "ridge.fit(X_train_pca, y_log)\n",
    "ridge_preds_log = ridge.predict(X_test_pca)\n",
    "ridge_preds_actual = np.expm1(ridge_preds_log)\n",
    "\n",
    "submission_ridge = pd.DataFrame({\n",
    "    'Id': test_df['Id'], \n",
    "    'HotelValue': ridge_preds_actual\n",
    "})\n",
    "submission_ridge.to_csv('submission_ridge.csv', index=False)\n",
    "print(\"\\n Ridge submission saved as 'submission_ridge.csv'\")\n",
    "print(submission_ridge.head())\n",
    "\n",
    "# --- Lasso Regression ---\n",
    "print(\"\\n=== Training Lasso Regression ===\")\n",
    "\n",
    "lasso = Lasso(alpha=0.0005, max_iter=5000) \n",
    "lasso.fit(X_train_pca, y_log)\n",
    "lasso_preds_log = lasso.predict(X_test_pca)\n",
    "lasso_preds_actual = np.expm1(lasso_preds_log)\n",
    "\n",
    "submission_lasso = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': lasso_preds_actual\n",
    "})\n",
    "submission_lasso.to_csv('submission_lasso.csv', index=False)\n",
    "print(\"\\n Lasso submission saved as 'submission_lasso.csv'\")\n",
    "print(submission_lasso.head())\n",
    "\n",
    "\n",
    "# --- Elastic Net Regression ---\n",
    "print(\"\\n=== Training Elastic Net Regression ===\")\n",
    "elastic_net = ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=5000) # Example parameters, tuning is essential!\n",
    "elastic_net.fit(X_train_pca, y_log)\n",
    "elastic_net_preds_log = elastic_net.predict(X_test_pca)\n",
    "elastic_net_preds_actual = np.expm1(elastic_net_preds_log)\n",
    "\n",
    "submission_elastic_net = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': elastic_net_preds_actual\n",
    "})\n",
    "submission_elastic_net.to_csv('submission_elastic_net.csv', index=False)\n",
    "print(\"\\n Elastic Net submission saved as 'submission_elastic_net.csv'\")\n",
    "print(submission_elastic_net.head())\n",
    "\n",
    "print(\"\\n=== Tuning Ridge Alpha ===\")\n",
    "param_grid_ridge = {'alpha': np.logspace(-4, 2, 50)} # Search over a range of alphas\n",
    "grid_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_ridge.fit(X_train_pca, y_log)\n",
    "\n",
    "print(f\"Best Ridge Alpha: {grid_ridge.best_params_['alpha']}\")\n",
    "print(f\"Best Ridge RMSE (negated): {grid_ridge.best_score_}\")\n",
    "\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "best_ridge_preds_log = best_ridge.predict(X_test_pca)\n",
    "best_ridge_preds_actual = np.expm1(best_ridge_preds_log)\n",
    "\n",
    "submission_best_ridge = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': best_ridge_preds_actual\n",
    "})\n",
    "submission_best_ridge.to_csv('submission_best_ridge.csv', index=False)\n",
    "print(\"\\n Best Ridge submission saved as 'submission_best_ridge.csv'\")\n",
    "print(submission_best_ridge.head())\n",
    "\n",
    "\n",
    "\n",
    "# --- Hyperparameter Tuning for Lasso ---\n",
    "print(\"\\n=== Tuning Lasso Alpha ===\")\n",
    "\n",
    "param_grid_lasso = {'alpha': np.logspace(-5, -1, 50)}\n",
    "grid_lasso = GridSearchCV(Lasso(max_iter=20000, tol=0.001), # Increased max_iter and tolerance\n",
    "                          param_grid_lasso,\n",
    "                          cv=5,\n",
    "                          scoring='neg_root_mean_squared_error',\n",
    "                          n_jobs=-1) # Use all available CPU cores\n",
    "grid_lasso.fit(X_train_pca, y_log)\n",
    "\n",
    "print(f\"Best Lasso Alpha: {grid_lasso.best_params_['alpha']}\")\n",
    "print(f\"Best Lasso RMSE (negated): {grid_lasso.best_score_}\")\n",
    "\n",
    "# Use the best Lasso estimator found by GridSearchCV\n",
    "best_lasso = grid_lasso.best_estimator_\n",
    "best_lasso_preds_log = best_lasso.predict(X_test_pca)\n",
    "best_lasso_preds_actual = np.expm1(best_lasso_preds_log)\n",
    "\n",
    "submission_best_lasso = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': best_lasso_preds_actual\n",
    "})\n",
    "submission_best_lasso.to_csv('submission_best_lasso.csv', index=False)\n",
    "print(\"\\n Best Lasso submission saved as 'submission_best_lasso.csv'\")\n",
    "print(submission_best_lasso.head())\n",
    "\n",
    "\n",
    "# --- Hyperparameter Tuning for ElasticNet ---\n",
    "print(\"\\n=== Tuning ElasticNet Alpha and L1 Ratio ===\")\n",
    "\n",
    "param_grid_enet = {\n",
    "    'alpha': np.logspace(-5, -1, 40), \n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99, 1.0] \n",
    "}\n",
    "grid_enet = GridSearchCV(ElasticNet(max_iter=50000, tol=0.001), \n",
    "                         param_grid_enet,\n",
    "                         cv=5,\n",
    "                         scoring='neg_root_mean_squared_error',\n",
    "                         n_jobs=-1) \n",
    "grid_enet.fit(X_train_pca, y_log)\n",
    "\n",
    "print(f\"Best ElasticNet Params: {grid_enet.best_params_}\")\n",
    "print(f\"Best ElasticNet RMSE (negated): {grid_enet.best_score_}\")\n",
    "\n",
    "# Use the best ElasticNet estimator found by GridSearchCV\n",
    "best_enet = grid_enet.best_estimator_\n",
    "best_enet_preds_log = best_enet.predict(X_test_pca)\n",
    "best_enet_preds_actual = np.expm1(best_enet_preds_log)\n",
    "\n",
    "# Create submission with the best ElasticNet model\n",
    "submission_best_enet = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': best_enet_preds_actual\n",
    "})\n",
    "submission_best_enet.to_csv('submission_best_enet.csv', index=False)\n",
    "print(\"\\n Best ElasticNet submission saved as 'submission_best_enet.csv'\")\n",
    "print(submission_best_enet.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13910868,
     "sourceId": 116111,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
