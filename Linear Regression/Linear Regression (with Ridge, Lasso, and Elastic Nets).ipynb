{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:16.929114Z",
     "iopub.status.busy": "2025-10-25T06:53:16.928796Z",
     "iopub.status.idle": "2025-10-25T06:53:16.939809Z",
     "shell.execute_reply": "2025-10-25T06:53:16.938648Z",
     "shell.execute_reply.started": "2025-10-25T06:53:16.929096Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:16.949476Z",
     "iopub.status.busy": "2025-10-25T06:53:16.949159Z",
     "iopub.status.idle": "2025-10-25T06:53:17.028485Z",
     "shell.execute_reply": "2025-10-25T06:53:17.026871Z",
     "shell.execute_reply.started": "2025-10-25T06:53:16.949453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 81 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       1200 non-null   int64  \n",
      " 1   PropertyClass            1200 non-null   int64  \n",
      " 2   ZoningCategory           1200 non-null   object \n",
      " 3   RoadAccessLength         977 non-null    float64\n",
      " 4   LandArea                 1200 non-null   int64  \n",
      " 5   RoadType                 1200 non-null   object \n",
      " 6   ServiceLaneType          75 non-null     object \n",
      " 7   PlotShape                1200 non-null   object \n",
      " 8   LandElevation            1200 non-null   object \n",
      " 9   UtilityAccess            1200 non-null   object \n",
      " 10  PlotConfiguration        1200 non-null   object \n",
      " 11  LandSlope                1200 non-null   object \n",
      " 12  District                 1200 non-null   object \n",
      " 13  NearbyTransport1         1200 non-null   object \n",
      " 14  NearbyTransport2         1200 non-null   object \n",
      " 15  PropertyType             1200 non-null   object \n",
      " 16  HotelStyle               1200 non-null   object \n",
      " 17  OverallQuality           1200 non-null   int64  \n",
      " 18  OverallCondition         1200 non-null   int64  \n",
      " 19  ConstructionYear         1200 non-null   int64  \n",
      " 20  RenovationYear           1200 non-null   int64  \n",
      " 21  RoofDesign               1200 non-null   object \n",
      " 22  RoofMaterial             1200 non-null   object \n",
      " 23  ExteriorPrimary          1200 non-null   object \n",
      " 24  ExteriorSecondary        1200 non-null   object \n",
      " 25  FacadeType               498 non-null    object \n",
      " 26  FacadeArea               1193 non-null   float64\n",
      " 27  ExteriorQuality          1200 non-null   object \n",
      " 28  ExteriorCondition        1200 non-null   object \n",
      " 29  FoundationType           1200 non-null   object \n",
      " 30  BasementHeight           1171 non-null   object \n",
      " 31  BasementCondition        1171 non-null   object \n",
      " 32  BasementExposure         1170 non-null   object \n",
      " 33  BasementFacilityType1    1171 non-null   object \n",
      " 34  BasementFacilitySF1      1200 non-null   int64  \n",
      " 35  BasementFacilityType2    1171 non-null   object \n",
      " 36  BasementFacilitySF2      1200 non-null   int64  \n",
      " 37  BasementUnfinishedSF     1200 non-null   int64  \n",
      " 38  BasementTotalSF          1200 non-null   int64  \n",
      " 39  HeatingType              1200 non-null   object \n",
      " 40  HeatingQuality           1200 non-null   object \n",
      " 41  CentralAC                1200 non-null   object \n",
      " 42  ElectricalSystem         1199 non-null   object \n",
      " 43  GroundFloorArea          1200 non-null   int64  \n",
      " 44  UpperFloorArea           1200 non-null   int64  \n",
      " 45  LowQualityArea           1200 non-null   int64  \n",
      " 46  UsableArea               1200 non-null   int64  \n",
      " 47  BasementFullBaths        1200 non-null   int64  \n",
      " 48  BasementHalfBaths        1200 non-null   int64  \n",
      " 49  FullBaths                1200 non-null   int64  \n",
      " 50  HalfBaths                1200 non-null   int64  \n",
      " 51  GuestRooms               1200 non-null   int64  \n",
      " 52  Kitchens                 1200 non-null   int64  \n",
      " 53  KitchenQuality           1200 non-null   object \n",
      " 54  TotalRooms               1200 non-null   int64  \n",
      " 55  PropertyFunctionality    1200 non-null   object \n",
      " 56  Lounges                  1200 non-null   int64  \n",
      " 57  LoungeQuality            640 non-null    object \n",
      " 58  ParkingType              1135 non-null   object \n",
      " 59  ParkingConstructionYear  1135 non-null   float64\n",
      " 60  ParkingFinish            1135 non-null   object \n",
      " 61  ParkingCapacity          1200 non-null   int64  \n",
      " 62  ParkingArea              1200 non-null   int64  \n",
      " 63  ParkingQuality           1135 non-null   object \n",
      " 64  ParkingCondition         1135 non-null   object \n",
      " 65  DrivewayType             1200 non-null   object \n",
      " 66  TerraceArea              1200 non-null   int64  \n",
      " 67  OpenVerandaArea          1200 non-null   int64  \n",
      " 68  EnclosedVerandaArea      1200 non-null   int64  \n",
      " 69  SeasonalPorchArea        1200 non-null   int64  \n",
      " 70  ScreenPorchArea          1200 non-null   int64  \n",
      " 71  SwimmingPoolArea         1200 non-null   int64  \n",
      " 72  PoolQuality              6 non-null      object \n",
      " 73  BoundaryFence            237 non-null    object \n",
      " 74  ExtraFacility            46 non-null     object \n",
      " 75  ExtraFacilityValue       1200 non-null   int64  \n",
      " 76  MonthSold                1200 non-null   int64  \n",
      " 77  YearSold                 1200 non-null   int64  \n",
      " 78  DealType                 1200 non-null   object \n",
      " 79  DealCondition            1200 non-null   object \n",
      " 80  HotelValue               1200 non-null   float64\n",
      "dtypes: float64(4), int64(34), object(43)\n",
      "memory usage: 759.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load and examine basic structure\n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.030843Z",
     "iopub.status.busy": "2025-10-25T06:53:17.030428Z",
     "iopub.status.idle": "2025-10-25T06:53:17.158932Z",
     "shell.execute_reply": "2025-10-25T06:53:17.157942Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.030809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 81 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       1200 non-null   int64  \n",
      " 1   PropertyClass            1200 non-null   int64  \n",
      " 2   ZoningCategory           1200 non-null   object \n",
      " 3   RoadAccessLength         977 non-null    float64\n",
      " 4   LandArea                 1200 non-null   int64  \n",
      " 5   RoadType                 1200 non-null   object \n",
      " 6   ServiceLaneType          75 non-null     object \n",
      " 7   PlotShape                1200 non-null   object \n",
      " 8   LandElevation            1200 non-null   object \n",
      " 9   UtilityAccess            1200 non-null   object \n",
      " 10  PlotConfiguration        1200 non-null   object \n",
      " 11  LandSlope                1200 non-null   object \n",
      " 12  District                 1200 non-null   object \n",
      " 13  NearbyTransport1         1200 non-null   object \n",
      " 14  NearbyTransport2         1200 non-null   object \n",
      " 15  PropertyType             1200 non-null   object \n",
      " 16  HotelStyle               1200 non-null   object \n",
      " 17  OverallQuality           1200 non-null   int64  \n",
      " 18  OverallCondition         1200 non-null   int64  \n",
      " 19  ConstructionYear         1200 non-null   int64  \n",
      " 20  RenovationYear           1200 non-null   int64  \n",
      " 21  RoofDesign               1200 non-null   object \n",
      " 22  RoofMaterial             1200 non-null   object \n",
      " 23  ExteriorPrimary          1200 non-null   object \n",
      " 24  ExteriorSecondary        1200 non-null   object \n",
      " 25  FacadeType               498 non-null    object \n",
      " 26  FacadeArea               1193 non-null   float64\n",
      " 27  ExteriorQuality          1200 non-null   object \n",
      " 28  ExteriorCondition        1200 non-null   object \n",
      " 29  FoundationType           1200 non-null   object \n",
      " 30  BasementHeight           1171 non-null   object \n",
      " 31  BasementCondition        1171 non-null   object \n",
      " 32  BasementExposure         1170 non-null   object \n",
      " 33  BasementFacilityType1    1171 non-null   object \n",
      " 34  BasementFacilitySF1      1200 non-null   int64  \n",
      " 35  BasementFacilityType2    1171 non-null   object \n",
      " 36  BasementFacilitySF2      1200 non-null   int64  \n",
      " 37  BasementUnfinishedSF     1200 non-null   int64  \n",
      " 38  BasementTotalSF          1200 non-null   int64  \n",
      " 39  HeatingType              1200 non-null   object \n",
      " 40  HeatingQuality           1200 non-null   object \n",
      " 41  CentralAC                1200 non-null   object \n",
      " 42  ElectricalSystem         1199 non-null   object \n",
      " 43  GroundFloorArea          1200 non-null   int64  \n",
      " 44  UpperFloorArea           1200 non-null   int64  \n",
      " 45  LowQualityArea           1200 non-null   int64  \n",
      " 46  UsableArea               1200 non-null   int64  \n",
      " 47  BasementFullBaths        1200 non-null   int64  \n",
      " 48  BasementHalfBaths        1200 non-null   int64  \n",
      " 49  FullBaths                1200 non-null   int64  \n",
      " 50  HalfBaths                1200 non-null   int64  \n",
      " 51  GuestRooms               1200 non-null   int64  \n",
      " 52  Kitchens                 1200 non-null   int64  \n",
      " 53  KitchenQuality           1200 non-null   object \n",
      " 54  TotalRooms               1200 non-null   int64  \n",
      " 55  PropertyFunctionality    1200 non-null   object \n",
      " 56  Lounges                  1200 non-null   int64  \n",
      " 57  LoungeQuality            640 non-null    object \n",
      " 58  ParkingType              1135 non-null   object \n",
      " 59  ParkingConstructionYear  1135 non-null   float64\n",
      " 60  ParkingFinish            1135 non-null   object \n",
      " 61  ParkingCapacity          1200 non-null   int64  \n",
      " 62  ParkingArea              1200 non-null   int64  \n",
      " 63  ParkingQuality           1135 non-null   object \n",
      " 64  ParkingCondition         1135 non-null   object \n",
      " 65  DrivewayType             1200 non-null   object \n",
      " 66  TerraceArea              1200 non-null   int64  \n",
      " 67  OpenVerandaArea          1200 non-null   int64  \n",
      " 68  EnclosedVerandaArea      1200 non-null   int64  \n",
      " 69  SeasonalPorchArea        1200 non-null   int64  \n",
      " 70  ScreenPorchArea          1200 non-null   int64  \n",
      " 71  SwimmingPoolArea         1200 non-null   int64  \n",
      " 72  PoolQuality              6 non-null      object \n",
      " 73  BoundaryFence            237 non-null    object \n",
      " 74  ExtraFacility            46 non-null     object \n",
      " 75  ExtraFacilityValue       1200 non-null   int64  \n",
      " 76  MonthSold                1200 non-null   int64  \n",
      " 77  YearSold                 1200 non-null   int64  \n",
      " 78  DealType                 1200 non-null   object \n",
      " 79  DealCondition            1200 non-null   object \n",
      " 80  HotelValue               1200 non-null   float64\n",
      "dtypes: float64(4), int64(34), object(43)\n",
      "memory usage: 759.5+ KB\n",
      "row:  BasementExposure \tmissing values: \t 30\n",
      "row:  BasementCondition \tmissing values: \t 29\n",
      "row:  BasementFacilityType1 \tmissing values: \t 29\n",
      "row:  BasementHeight \tmissing values: \t 29\n",
      "row:  BasementFacilityType2 \tmissing values: \t 29\n",
      "row:  FacadeArea \tmissing values: \t 7\n",
      "row:  ElectricalSystem \tmissing values: \t 1\n",
      "row:  UsableArea \tmissing values: \t 0\n",
      "row:  LowQualityArea \tmissing values: \t 0\n",
      "row:  KitchenQuality \tmissing values: \t 0\n",
      "row:  UpperFloorArea \tmissing values: \t 0\n",
      "row:  BasementFullBaths \tmissing values: \t 0\n",
      "row:  BasementHalfBaths \tmissing values: \t 0\n",
      "row:  FullBaths \tmissing values: \t 0\n",
      "row:  GroundFloorArea \tmissing values: \t 0\n",
      "row:  HalfBaths \tmissing values: \t 0\n",
      "row:  GuestRooms \tmissing values: \t 0\n",
      "row:  Kitchens \tmissing values: \t 0\n",
      "row:  Id \tmissing values: \t 0\n",
      "row:  CentralAC \tmissing values: \t 0\n",
      "row:  PropertyFunctionality \tmissing values: \t 0\n",
      "row:  DealCondition \tmissing values: \t 0\n",
      "row:  DealType \tmissing values: \t 0\n",
      "row:  YearSold \tmissing values: \t 0\n",
      "row:  MonthSold \tmissing values: \t 0\n",
      "row:  ExtraFacilityValue \tmissing values: \t 0\n",
      "row:  SwimmingPoolArea \tmissing values: \t 0\n",
      "row:  ScreenPorchArea \tmissing values: \t 0\n",
      "row:  SeasonalPorchArea \tmissing values: \t 0\n",
      "row:  EnclosedVerandaArea \tmissing values: \t 0\n",
      "row:  OpenVerandaArea \tmissing values: \t 0\n",
      "row:  TerraceArea \tmissing values: \t 0\n",
      "row:  DrivewayType \tmissing values: \t 0\n",
      "row:  ParkingArea \tmissing values: \t 0\n",
      "row:  ParkingCapacity \tmissing values: \t 0\n",
      "row:  Lounges \tmissing values: \t 0\n",
      "row:  TotalRooms \tmissing values: \t 0\n",
      "row:  BasementUnfinishedSF \tmissing values: \t 0\n",
      "row:  HeatingQuality \tmissing values: \t 0\n",
      "row:  OverallQuality \tmissing values: \t 0\n",
      "row:  ZoningCategory \tmissing values: \t 0\n",
      "row:  LandArea \tmissing values: \t 0\n",
      "row:  RoadType \tmissing values: \t 0\n",
      "row:  PlotShape \tmissing values: \t 0\n",
      "row:  LandElevation \tmissing values: \t 0\n",
      "row:  UtilityAccess \tmissing values: \t 0\n",
      "row:  PlotConfiguration \tmissing values: \t 0\n",
      "row:  LandSlope \tmissing values: \t 0\n",
      "row:  District \tmissing values: \t 0\n",
      "row:  NearbyTransport1 \tmissing values: \t 0\n",
      "row:  NearbyTransport2 \tmissing values: \t 0\n",
      "row:  PropertyType \tmissing values: \t 0\n",
      "row:  HotelStyle \tmissing values: \t 0\n",
      "row:  OverallCondition \tmissing values: \t 0\n",
      "row:  HeatingType \tmissing values: \t 0\n",
      "row:  ConstructionYear \tmissing values: \t 0\n",
      "row:  RenovationYear \tmissing values: \t 0\n",
      "row:  RoofDesign \tmissing values: \t 0\n",
      "row:  RoofMaterial \tmissing values: \t 0\n",
      "row:  ExteriorPrimary \tmissing values: \t 0\n",
      "row:  ExteriorSecondary \tmissing values: \t 0\n",
      "row:  ExteriorQuality \tmissing values: \t 0\n",
      "row:  ExteriorCondition \tmissing values: \t 0\n",
      "row:  FoundationType \tmissing values: \t 0\n",
      "row:  BasementFacilitySF1 \tmissing values: \t 0\n",
      "row:  BasementFacilitySF2 \tmissing values: \t 0\n",
      "row:  PropertyClass \tmissing values: \t 0\n",
      "row:  BasementTotalSF \tmissing values: \t 0\n",
      "row:  HotelValue \tmissing values: \t 0\n",
      "Columns to drop\n",
      "Index(['ServiceLaneType', 'FacadeType', 'LoungeQuality', 'PoolQuality',\n",
      "       'BoundaryFence', 'ExtraFacility'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df.shape\n",
    "train_df.info()\n",
    "null_value_percentages=(train_df.isna().sum()/train_df.shape[0])*100\n",
    "null_value_percentages\n",
    "rows_to_drop=null_value_percentages[null_value_percentages<5].sort_values(ascending=False)\n",
    "rows_to_drop\n",
    "rows_to_drop=rows_to_drop.keys()\n",
    "rows_to_drop\n",
    "for row in rows_to_drop:\n",
    "\tprint(\"row: \",row,\"\\tmissing values: \\t\",train_df[row].isna().sum())\n",
    "train_df.shape\n",
    "for row in rows_to_drop:\n",
    "    if(null_value_percentages[row]<6):\n",
    "        train_df.drop(labels=train_df.index[train_df[row].isna()],inplace=True)\n",
    "\n",
    "train_df.shape\n",
    "columns_to_drop=null_value_percentages[null_value_percentages>40]\n",
    "columns_to_drop=columns_to_drop.keys()\n",
    "\n",
    "print(\"Columns to drop\")\n",
    "print(columns_to_drop)\n",
    "train_df.drop(columns=columns_to_drop,inplace=True)\n",
    "test_df.drop(columns=columns_to_drop,inplace=True)\n",
    "\n",
    "train_df.shape\n",
    "train_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.160777Z",
     "iopub.status.busy": "2025-10-25T06:53:17.160202Z",
     "iopub.status.idle": "2025-10-25T06:53:17.169217Z",
     "shell.execute_reply": "2025-10-25T06:53:17.167963Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.160746Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.replace({\n",
    "#     \"ParkingQuality\": {np.nan: \"NoParking\"},\n",
    "#     \"ParkingCondition\": {np.nan: \"NoParking\"}\n",
    "# }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.171818Z",
     "iopub.status.busy": "2025-10-25T06:53:17.171416Z",
     "iopub.status.idle": "2025-10-25T06:53:17.200849Z",
     "shell.execute_reply": "2025-10-25T06:53:17.199286Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.171789Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_df.replace({\n",
    "#     \"ParkingQuality\": {np.nan: \"NoParking\"},\n",
    "#     \"ParkingCondition\": {np.nan: \"NoParking\"}\n",
    "# }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.203505Z",
     "iopub.status.busy": "2025-10-25T06:53:17.203009Z",
     "iopub.status.idle": "2025-10-25T06:53:17.245242Z",
     "shell.execute_reply": "2025-10-25T06:53:17.243575Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.203465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original maximum value: 745000.0\n",
      "Maximum value after capping: 618227.2130000071\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.hist(train_df['HotelValue'], bins=50)\n",
    "percentile_threshold = train_df['HotelValue'].quantile(0.999)\n",
    "print(\"Original maximum value:\", train_df['HotelValue'].max())\n",
    "# Cap the values at the 99.9th percentile\n",
    "train_df['HotelValue'] = train_df['HotelValue'].clip(upper=percentile_threshold)\n",
    "print(\"Maximum value after capping:\", train_df['HotelValue'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.247233Z",
     "iopub.status.busy": "2025-10-25T06:53:17.246855Z",
     "iopub.status.idle": "2025-10-25T06:53:17.289066Z",
     "shell.execute_reply": "2025-10-25T06:53:17.287942Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.247202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         missing_percent    dtype\n",
      "RoadAccessLength               18.588640  float64\n",
      "ParkingConstructionYear         4.991394  float64\n"
     ]
    }
   ],
   "source": [
    "missing_summary = (\n",
    "    train_df.isnull().sum() / len(train_df) * 100\n",
    ").sort_values(ascending=False).to_frame(\"missing_percent\")\n",
    "\n",
    "# Add dtypes for reference\n",
    "missing_summary[\"dtype\"] = train_df.dtypes\n",
    "\n",
    "# Focus only on numeric columns with some missingness\n",
    "numeric_missing = missing_summary[\n",
    "    (missing_summary[\"missing_percent\"] > 0) &\n",
    "    ((missing_summary[\"dtype\"]==\"float64\") |\n",
    "    (missing_summary[\"dtype\"]==\"int64\"))\n",
    "]\n",
    "\n",
    "print(numeric_missing)\n",
    "\n",
    "'''There are three features with missing values for numeric values.\n",
    "The first is RoadAccessLength which is the length of road access available to the property. It could be that some properties do not have road\n",
    "access at all, in which case we should fill 0 in all these columns, however we see that the column \"RoadType\" has no null values, which means \n",
    "every property has some road leading up to it. So the values are missing randomly, and not due to there being no road available. The missing\n",
    "percentage is not very high (18.58%) so we can impute the values using median.'''\n",
    "\n",
    "road_access_median = train_df[\"RoadAccessLength\"].median()\n",
    "train_df[\"RoadAccessLength\"] = train_df[\"RoadAccessLength\"].fillna(road_access_median)\n",
    "test_df[\"RoadAccessLength\"] = test_df[\"RoadAccessLength\"].fillna(road_access_median)\n",
    "\n",
    "'''FacadeArea only missing for rows with FacadeType null, we can impute 0 here as they probably have no facade.'''\n",
    "train_df[\"FacadeArea\"] = train_df[\"FacadeArea\"].fillna(0)\n",
    "test_df[\"FacadeArea\"] = test_df[\"FacadeArea\"].fillna(0)\n",
    "\n",
    "'''ParkingConstructionYear imputed with median with ConstructionYear as there seems to be high correlation'''\n",
    "train_df['ParkingConstructionYear'] = train_df['ParkingConstructionYear'].fillna(train_df['ConstructionYear'])\n",
    "test_df['ParkingConstructionYear'] = test_df['ParkingConstructionYear'].fillna(test_df['ConstructionYear'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.290648Z",
     "iopub.status.busy": "2025-10-25T06:53:17.290284Z",
     "iopub.status.idle": "2025-10-25T06:53:17.317467Z",
     "shell.execute_reply": "2025-10-25T06:53:17.316293Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.290616Z"
    }
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "# numeric_cols = numeric_cols.drop('HotelValue')\n",
    "\n",
    "# nunique_threshold = 15\n",
    "# discrete_numeric_cols = []\n",
    "# for col in numeric_cols:\n",
    "#     if train_df[col].nunique() < nunique_threshold and col != 'HotelValue':\n",
    "#         discrete_numeric_cols.append(col)\n",
    "\n",
    "# print(f\"Found {len(discrete_numeric_cols)} discrete numeric columns:\")\n",
    "# continuous_numeric_cols = [\n",
    "#     col for col in numeric_cols \n",
    "#     if train_df[col].nunique() >= nunique_threshold\n",
    "# ]\n",
    "\n",
    "# # Dynamically determine the grid size for the subplots\n",
    "# n_cols = len(continuous_numeric_cols)\n",
    "# n_rows = math.ceil(n_cols / 3) # Creates a grid with 3 columns\n",
    "\n",
    "# fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5 * n_rows))\n",
    "# axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "# for idx, feature in enumerate(continuous_numeric_cols):\n",
    "#  axes[idx].scatter(train_df[feature], train_df['HotelValue'], alpha=0.5)\n",
    "#  axes[idx].set_xlabel(feature)\n",
    "#  axes[idx].set_ylabel('HotelValue')\n",
    "#  axes[idx].set_title(f'{feature} vs HotelValue')\n",
    "\n",
    "# # Hide any unused subplots\n",
    "# for i in range(n_cols, len(axes)):\n",
    "#  fig.delaxes(axes[i])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.319151Z",
     "iopub.status.busy": "2025-10-25T06:53:17.318785Z",
     "iopub.status.idle": "2025-10-25T06:53:17.373996Z",
     "shell.execute_reply": "2025-10-25T06:53:17.372892Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.319124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 70)\n",
      "(260, 69)\n"
     ]
    }
   ],
   "source": [
    "# '''Adding binary indicators for whether certain features exist for a house or not as there are a lot of facilities like terrace, parking\n",
    "# etc. which do not exist for quite a few houses.'''\n",
    "# # List all features with this pattern\n",
    "# area_features = ['EnclosedVerandaArea', 'SeasonalPorchArea', 'ScreenPorchArea', \n",
    "#                  'TerraceArea', 'BasementTotalSF', \n",
    "#                  'ParkingArea', 'OpenVerandaArea', 'FacadeArea', 'BasementFacilitySF1', 'BasementFacilitySF2', \n",
    "#                  'BasementUnfinishedSF', 'UpperFloorArea', 'LowQualityArea', 'SwimmingPoolArea', 'ExtraFacilityValue']\n",
    "\n",
    "# for feature in area_features:\n",
    "#     train_df[f'Has{feature.replace(\"Area\", \"\").replace(\"SF\", \"\")}'] = (train_df[feature] > 0).astype(int)\n",
    "#     test_df[f'Has{feature.replace(\"Area\", \"\").replace(\"SF\", \"\")}'] = (test_df[feature] > 0).astype(int)\n",
    "\n",
    "#SwimmingPoolArea and ExtraFacilityValue show hardly any correlation to the target variable even for houses that do have those facilities.\n",
    "#Thus, these can be dropped.\n",
    "\n",
    "train_df = train_df.drop(columns=['LowQualityArea', 'SeasonalPorchArea', 'ScreenPorchArea', 'SwimmingPoolArea', 'ExtraFacilityValue'])\n",
    "test_df = test_df.drop(columns=['LowQualityArea', 'SeasonalPorchArea', 'ScreenPorchArea', 'SwimmingPoolArea', 'ExtraFacilityValue'])\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.375182Z",
     "iopub.status.busy": "2025-10-25T06:53:17.374874Z",
     "iopub.status.idle": "2025-10-25T06:53:17.410175Z",
     "shell.execute_reply": "2025-10-25T06:53:17.407924Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.375161Z"
    }
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# discrete_numeric_cols.remove('SwimmingPoolArea')\n",
    "# n_features = len(discrete_numeric_cols)\n",
    "# n_cols = 2\n",
    "# n_rows = math.ceil(n_features / n_cols)\n",
    "\n",
    "# # Create the figure and axes\n",
    "# fig, axes = plt.subplots(n_rows, n_cols, figsize=(8 * n_cols, 6 * n_rows))\n",
    "# axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "# # Loop through the identified columns and create a boxplot for each\n",
    "# for idx, feature in enumerate(discrete_numeric_cols):\n",
    "#     sns.boxplot(x=feature, y='HotelValue', data=train_df, ax=axes[idx])\n",
    "#     axes[idx].set_title(f'HotelValue vs {feature}', fontsize=14)\n",
    "#     axes[idx].set_xlabel(feature, fontsize=12)\n",
    "#     axes[idx].set_ylabel('HotelValue', fontsize=12)\n",
    "\n",
    "# # Hide any unused subplots\n",
    "# for i in range(n_features, len(axes)):\n",
    "#     fig.delaxes(axes[i])\n",
    "\n",
    "# # Adjust layout to prevent overlap and display the plots\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.414594Z",
     "iopub.status.busy": "2025-10-25T06:53:17.414096Z",
     "iopub.status.idle": "2025-10-25T06:53:17.453968Z",
     "shell.execute_reply": "2025-10-25T06:53:17.452752Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.414566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 67)\n",
      "(260, 66)\n"
     ]
    }
   ],
   "source": [
    "#We will drop features which show very little variation across categories as these are unlikely to be string predictors of the target variable.\n",
    "train_df = train_df.drop(columns=['MonthSold', 'BasementHalfBaths', 'YearSold'])\n",
    "test_df = test_df.drop(columns=['MonthSold', 'BasementHalfBaths', 'YearSold'])\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.455194Z",
     "iopub.status.busy": "2025-10-25T06:53:17.454928Z",
     "iopub.status.idle": "2025-10-25T06:53:17.493242Z",
     "shell.execute_reply": "2025-10-25T06:53:17.492092Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.455174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  missing_percent   dtype\n",
      "ParkingFinish            4.991394  object\n",
      "ParkingType              4.991394  object\n",
      "ParkingQuality           4.991394  object\n",
      "ParkingCondition         4.991394  object\n",
      "ParkingType         58\n",
      "ParkingFinish       58\n",
      "ParkingQuality      58\n",
      "ParkingCondition    58\n",
      "dtype: int64\n",
      "BasementHeight            8\n",
      "BasementCondition         8\n",
      "BasementExposure          8\n",
      "BasementFacilityType1     8\n",
      "BasementFacilityType2     9\n",
      "ParkingType              16\n",
      "ParkingFinish            16\n",
      "ParkingQuality           16\n",
      "ParkingCondition         16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categorical_missing = missing_summary[\n",
    "    (missing_summary[\"missing_percent\"] > 0) &\n",
    "    (missing_summary[\"dtype\"]==\"object\")    \n",
    "]\n",
    "\n",
    "print(categorical_missing)\n",
    "\n",
    "\n",
    "missing_counts = train_df.isnull().sum()\n",
    "print(missing_counts[missing_counts > 0]) \n",
    "\n",
    "missing_counts_test = test_df.isnull().sum()\n",
    "print(missing_counts_test[missing_counts_test > 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.495131Z",
     "iopub.status.busy": "2025-10-25T06:53:17.494619Z",
     "iopub.status.idle": "2025-10-25T06:53:17.522189Z",
     "shell.execute_reply": "2025-10-25T06:53:17.520729Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.495044Z"
    }
   },
   "outputs": [],
   "source": [
    "# categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# print(f\"Found {len(categorical_cols)} columns with 'object' data type:\")\n",
    "# target_variable = 'HotelValue'\n",
    "\n",
    "# # Determine the grid size for the subplots (arranging them in 2 columns)\n",
    "# n_features = len(categorical_cols)\n",
    "# n_cols = 2\n",
    "# n_rows = math.ceil(n_features / n_cols)\n",
    "\n",
    "# # Create the figure and axes\n",
    "# fig, axes = plt.subplots(n_rows, n_cols, figsize=(8 * n_cols, 6 * n_rows))\n",
    "# axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "# # Loop through the identified columns and create a boxplot for each\n",
    "# for idx, feature in enumerate(categorical_cols):\n",
    "#     # It's good practice to sort the categories for a cleaner plot, e.g., by median value\n",
    "#     # This is optional but makes the plot easier to interpret\n",
    "#     sorted_order = train_df.groupby(feature)[target_variable].median().sort_values().index\n",
    "    \n",
    "#     sns.boxplot(x=feature, y=target_variable, data=train_df, ax=axes[idx], order=sorted_order)\n",
    "    \n",
    "#     axes[idx].set_title(f'{target_variable} vs {feature}', fontsize=14)\n",
    "#     axes[idx].set_xlabel(feature, fontsize=12)\n",
    "#     axes[idx].set_ylabel(target_variable, fontsize=12)\n",
    "    \n",
    "#     # Optional: Rotate x-axis labels if they are long and overlap\n",
    "#     axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# # Hide any unused subplots\n",
    "# for i in range(n_features, len(axes)):\n",
    "#     fig.delaxes(axes[i])\n",
    "\n",
    "# # Adjust layout to prevent overlap and display the plots\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.525189Z",
     "iopub.status.busy": "2025-10-25T06:53:17.524761Z",
     "iopub.status.idle": "2025-10-25T06:53:17.561416Z",
     "shell.execute_reply": "2025-10-25T06:53:17.560069Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.525162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 65)\n",
      "(260, 64)\n"
     ]
    }
   ],
   "source": [
    "#We will drop columns with very little variance across categories\n",
    "train_df = train_df.drop(columns=['UtilityAccess', 'RoadType'])\n",
    "test_df = test_df.drop(columns=['UtilityAccess', 'RoadType'])\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.563221Z",
     "iopub.status.busy": "2025-10-25T06:53:17.562918Z",
     "iopub.status.idle": "2025-10-25T06:53:17.593419Z",
     "shell.execute_reply": "2025-10-25T06:53:17.592558Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.563190Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values per column:\n",
      " Series([], dtype: int64)\n",
      "Infinite values per column:\n",
      " Series([], dtype: int64)\n",
      "(1162, 64)\n",
      "(260, 63)\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "negative_values = (train_df[numeric_cols] < 0).sum()\n",
    "print(\"Negative values per column:\\n\", negative_values[negative_values > 0])\n",
    "\n",
    "# Check for infinite values\n",
    "infinite_values = np.isinf(train_df[numeric_cols]).sum()\n",
    "print(\"Infinite values per column:\\n\", infinite_values[infinite_values > 0])\n",
    "\n",
    "# # Visualize\n",
    "# plt.figure(figsize=(20, 16))\n",
    "# sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()\n",
    "\n",
    "# # Find high correlations (excluding diagonal)\n",
    "# high_corr = []\n",
    "# for i in range(len(corr_matrix.columns)):\n",
    "#     for j in range(i+1, len(corr_matrix.columns)):\n",
    "#         if abs(corr_matrix.iloc[i, j]) > 0.75:  # threshold\n",
    "#             high_corr.append({\n",
    "#                 'Feature1': corr_matrix.columns[i],\n",
    "#                 'Feature2': corr_matrix.columns[j],\n",
    "#                 'Correlation': corr_matrix.iloc[i, j]\n",
    "#             })\n",
    "\n",
    "# print(\"Highly correlated pairs (>0.75):\")\n",
    "# for pair in high_corr:\n",
    "#     print(f\"{pair['Feature1']} <-> {pair['Feature2']}: {pair['Correlation']:.3f}\")\n",
    "\n",
    "train_df=train_df.drop(columns=['ParkingConstructionYear'])\n",
    "test_df=test_df.drop(columns=['ParkingConstructionYear'])\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled remaining categorical NaNs.\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Fill NaNs with the mode (most frequent value) for each column\n",
    "for col in categorical_cols:\n",
    "    mode_value_train = train_df[col].mode()[0]\n",
    "    train_df[col] = train_df[col].fillna(mode_value_train)\n",
    "\n",
    "    # Use the TRAIN mode to fill the TEST set to prevent data leakage\n",
    "    test_df[col] = test_df[col].fillna(mode_value_train)\n",
    "\n",
    "print(\"Filled remaining categorical NaNs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 62)\n",
      "(1162,)\n",
      "(260, 62)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop(columns=['HotelValue','Id'])\n",
    "test_ids = test_df['Id'].copy()\n",
    "y = train_df['HotelValue']\n",
    "y = np.log1p(y)\n",
    "X_test = test_df.drop(columns=['Id'])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T06:53:17.878691Z",
     "iopub.status.busy": "2025-10-25T06:53:17.878292Z",
     "iopub.status.idle": "2025-10-25T06:53:18.015886Z",
     "shell.execute_reply": "2025-10-25T06:53:18.013987Z",
     "shell.execute_reply.started": "2025-10-25T06:53:17.878638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical encoding complete with 35 columns\n",
      "\n",
      "=== Training Linear Regression ===\n",
      "\n",
      "Test Predictions:\n",
      "Sample: [149162.62542024 328296.25071827 117718.82322156 172772.39996541\n",
      " 317096.21408501]\n",
      "Min: $51060.86\n",
      "Max: $690402.71\n",
      "Mean: $175272.67\n",
      "\n",
      " Submission saved as 'submission.csv'\n",
      "     Id     HotelValue\n",
      "0   893  149162.625420\n",
      "1  1106  328296.250718\n",
      "2   414  117718.823222\n",
      "3   523  172772.399965\n",
      "4  1037  317096.214085\n",
      "5   615   89749.759285\n",
      "6   219  239028.736702\n",
      "7  1161  151633.547376\n",
      "8   650   90792.346860\n",
      "9   888  136216.538760\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare data\n",
    "X = train_df.drop(['HotelValue', 'Id'], axis=1)\n",
    "y = train_df['HotelValue']\n",
    "X_test = test_df.drop(columns=['Id'])\n",
    "\n",
    "# Apply log transformation to target\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Handle categorical variables - FIX for unseen categories\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Combine train and test to fit encoder on all categories\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Fit on combined data to see all categories\n",
    "    combined = pd.concat([X[col], X_test[col]], axis=0).astype(str)\n",
    "    le.fit(combined)\n",
    "    \n",
    "    # Transform both datasets\n",
    "    X[col] = le.transform(X[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "\n",
    "print(f\"Categorical encoding complete with {len(categorical_columns)} columns\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train linear regression (without scaling)\n",
    "print(\"\\n=== Training Linear Regression ===\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_log)\n",
    "\n",
    "\n",
    "# Make test predictions\n",
    "preds = lr_model.predict(X_test_scaled)\n",
    "y_test_pred_actual = np.expm1(preds)\n",
    "\n",
    "print(f\"\\nTest Predictions:\")\n",
    "print(f\"Sample: {y_test_pred_actual[:5]}\")\n",
    "print(f\"Min: ${y_test_pred_actual.min():.2f}\")\n",
    "print(f\"Max: ${y_test_pred_actual.max():.2f}\")\n",
    "print(f\"Mean: ${y_test_pred_actual.mean():.2f}\")\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'HotelValue': y_test_pred_actual\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_linear_regression.csv', index=False)\n",
    "print(\"\\n Submission saved as 'submission.csv'\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Ridge Regression ===\n",
      "\n",
      " Ridge submission saved as 'submission_ridge.csv'\n",
      "     Id     HotelValue\n",
      "0   893  148988.826015\n",
      "1  1106  327852.080058\n",
      "2   414  117789.494964\n",
      "3   523  172602.592697\n",
      "4  1037  317147.788193\n",
      "\n",
      "=== Training Lasso Regression ===\n",
      "\n",
      " Lasso submission saved as 'submission_lasso.csv'\n",
      "     Id     HotelValue\n",
      "0   893  149017.763298\n",
      "1  1106  326988.683598\n",
      "2   414  117928.593614\n",
      "3   523  172793.733945\n",
      "4  1037  317029.519988\n",
      "\n",
      "=== Training Elastic Net Regression ===\n",
      "\n",
      " Elastic Net submission saved as 'submission_elastic_net.csv'\n",
      "     Id     HotelValue\n",
      "0   893  149003.704903\n",
      "1  1106  326970.408033\n",
      "2   414  117929.269968\n",
      "3   523  172762.985153\n",
      "4  1037  317029.780172\n",
      "\n",
      "=== Tuning Ridge Alpha ===\n",
      "Best Ridge Alpha: 100.0\n",
      "Best Ridge RMSE (negated): -0.1503243042866083\n",
      "\n",
      " Best Ridge submission saved as 'submission_best_ridge.csv'\n",
      "     Id     HotelValue\n",
      "0   893  147825.628303\n",
      "1  1106  326563.565513\n",
      "2   414  117607.705413\n",
      "3   523  169718.320937\n",
      "4  1037  315633.832610\n",
      "\n",
      "=== Tuning Lasso Alpha ===\n",
      "Best Lasso Alpha: 0.004941713361323833\n",
      "Best Lasso RMSE (negated): -0.15056940772935012\n",
      "\n",
      " Best Lasso submission saved as 'submission_best_lasso.csv'\n",
      "     Id     HotelValue\n",
      "0   893  146444.748349\n",
      "1  1106  318886.562842\n",
      "2   414  119769.312589\n",
      "3   523  170165.519244\n",
      "4  1037  316706.192898\n",
      "\n",
      "=== Tuning ElasticNet Alpha and L1 Ratio ===\n",
      "Best ElasticNet Params: {'alpha': 0.049238826317067365, 'l1_ratio': 0.1}\n",
      "Best ElasticNet RMSE (negated): -0.14995238283944767\n",
      "\n",
      " Best ElasticNet submission saved as 'submission_best_enet.csv'\n",
      "     Id     HotelValue\n",
      "0   893  145144.045441\n",
      "1  1106  317529.880445\n",
      "2   414  119512.552684\n",
      "3   523  168240.076681\n",
      "4  1037  316180.516637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Ridge Regression ---\n",
    "print(\"\\n=== Training Ridge Regression ===\")\n",
    "ridge = Ridge(alpha=1.0) # Start with a default alpha\n",
    "ridge.fit(X_train_scaled, y_log)\n",
    "ridge_preds_log = ridge.predict(X_test_scaled)\n",
    "ridge_preds_actual = np.expm1(ridge_preds_log)\n",
    "\n",
    "# Create submission\n",
    "submission_ridge = pd.DataFrame({\n",
    "    'Id': test_df['Id'], \n",
    "    'HotelValue': ridge_preds_actual\n",
    "})\n",
    "submission_ridge.to_csv('submission_ridge.csv', index=False)\n",
    "print(\"\\n Ridge submission saved as 'submission_ridge.csv'\")\n",
    "print(submission_ridge.head())\n",
    "\n",
    "# --- Lasso Regression ---\n",
    "print(\"\\n=== Training Lasso Regression ===\")\n",
    "\n",
    "lasso = Lasso(alpha=0.0005, max_iter=5000) \n",
    "lasso.fit(X_train_scaled, y_log)\n",
    "lasso_preds_log = lasso.predict(X_test_scaled)\n",
    "lasso_preds_actual = np.expm1(lasso_preds_log)\n",
    "\n",
    "# Create submission\n",
    "submission_lasso = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': lasso_preds_actual\n",
    "})\n",
    "submission_lasso.to_csv('submission_lasso.csv', index=False)\n",
    "print(\"\\n Lasso submission saved as 'submission_lasso.csv'\")\n",
    "print(submission_lasso.head())\n",
    "\n",
    "\n",
    "# --- Elastic Net Regression ---\n",
    "print(\"\\n=== Training Elastic Net Regression ===\")\n",
    "# Elastic Net requires tuning both alpha and l1_ratio\n",
    "elastic_net = ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=5000) # Example parameters, tuning is essential!\n",
    "elastic_net.fit(X_train_scaled, y_log)\n",
    "elastic_net_preds_log = elastic_net.predict(X_test_scaled)\n",
    "elastic_net_preds_actual = np.expm1(elastic_net_preds_log)\n",
    "\n",
    "# Create submission\n",
    "submission_elastic_net = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': elastic_net_preds_actual\n",
    "})\n",
    "submission_elastic_net.to_csv('submission_elastic_net.csv', index=False)\n",
    "print(\"\\n Elastic Net submission saved as 'submission_elastic_net.csv'\")\n",
    "print(submission_elastic_net.head())\n",
    "\n",
    "print(\"\\n=== Tuning Ridge Alpha ===\")\n",
    "param_grid_ridge = {'alpha': np.logspace(-4, 2, 50)} # Search over a range of alphas\n",
    "grid_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_ridge.fit(X_train_scaled, y_log)\n",
    "\n",
    "print(f\"Best Ridge Alpha: {grid_ridge.best_params_['alpha']}\")\n",
    "print(f\"Best Ridge RMSE (negated): {grid_ridge.best_score_}\")\n",
    "\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "best_ridge_preds_log = best_ridge.predict(X_test_scaled)\n",
    "best_ridge_preds_actual = np.expm1(best_ridge_preds_log)\n",
    "\n",
    "# Create submission with the best ridge model\n",
    "submission_best_ridge = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': best_ridge_preds_actual\n",
    "})\n",
    "submission_best_ridge.to_csv('submission_best_ridge.csv', index=False)\n",
    "print(\"\\n Best Ridge submission saved as 'submission_best_ridge.csv'\")\n",
    "print(submission_best_ridge.head())\n",
    "\n",
    "\n",
    "\n",
    "# --- Hyperparameter Tuning for Lasso ---\n",
    "print(\"\\n=== Tuning Lasso Alpha ===\")\n",
    "# Adjust the range and number of points in np.logspace as needed based on performance\n",
    "# Smaller alphas are closer to OLS, larger alphas increase regularization (more feature shrinking/selection)\n",
    "# Increased max_iter significantly to help convergence, especially with small alphas\n",
    "param_grid_lasso = {'alpha': np.logspace(-5, -1, 50)}\n",
    "grid_lasso = GridSearchCV(Lasso(max_iter=10000, tol=0.001), # Increased max_iter and tolerance\n",
    "                          param_grid_lasso,\n",
    "                          cv=5,\n",
    "                          scoring='neg_root_mean_squared_error',\n",
    "                          n_jobs=-1) # Use all available CPU cores\n",
    "grid_lasso.fit(X_train_scaled, y_log)\n",
    "\n",
    "print(f\"Best Lasso Alpha: {grid_lasso.best_params_['alpha']}\")\n",
    "print(f\"Best Lasso RMSE (negated): {grid_lasso.best_score_}\")\n",
    "\n",
    "# Use the best Lasso estimator found by GridSearchCV\n",
    "best_lasso = grid_lasso.best_estimator_\n",
    "best_lasso_preds_log = best_lasso.predict(X_test_scaled)\n",
    "best_lasso_preds_actual = np.expm1(best_lasso_preds_log)\n",
    "\n",
    "# Create submission with the best lasso model\n",
    "submission_best_lasso = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': best_lasso_preds_actual\n",
    "})\n",
    "submission_best_lasso.to_csv('submission_best_lasso.csv', index=False)\n",
    "print(\"\\n Best Lasso submission saved as 'submission_best_lasso.csv'\")\n",
    "print(submission_best_lasso.head())\n",
    "\n",
    "\n",
    "# --- Hyperparameter Tuning for ElasticNet ---\n",
    "print(\"\\n=== Tuning ElasticNet Alpha and L1 Ratio ===\")\n",
    "# ElasticNet combines L1 (Lasso) and L2 (Ridge) penalties.\n",
    "# l1_ratio = 1 is Lasso, l1_ratio = 0 is Ridge. Values in between mix them.\n",
    "# Adjust alpha range and l1_ratio list based on performance.\n",
    "# Increased max_iter significantly.\n",
    "param_grid_enet = {\n",
    "    'alpha': np.logspace(-5, -1, 40), # Might need adjustment\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99, 1.0] # Test various mixes, including Lasso-like (1.0)\n",
    "}\n",
    "grid_enet = GridSearchCV(ElasticNet(max_iter=50000, tol=0.001), # Increased max_iter and tolerance\n",
    "                         param_grid_enet,\n",
    "                         cv=5,\n",
    "                         scoring='neg_root_mean_squared_error',\n",
    "                         n_jobs=-1) # Use all available CPU cores\n",
    "grid_enet.fit(X_train_scaled, y_log)\n",
    "\n",
    "print(f\"Best ElasticNet Params: {grid_enet.best_params_}\")\n",
    "print(f\"Best ElasticNet RMSE (negated): {grid_enet.best_score_}\")\n",
    "\n",
    "# Use the best ElasticNet estimator found by GridSearchCV\n",
    "best_enet = grid_enet.best_estimator_\n",
    "best_enet_preds_log = best_enet.predict(X_test_scaled)\n",
    "best_enet_preds_actual = np.expm1(best_enet_preds_log)\n",
    "\n",
    "# Create submission with the best ElasticNet model\n",
    "submission_best_enet = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'HotelValue': best_enet_preds_actual\n",
    "})\n",
    "submission_best_enet.to_csv('submission_best_enet.csv', index=False)\n",
    "print(\"\\n Best ElasticNet submission saved as 'submission_best_enet.csv'\")\n",
    "print(submission_best_enet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13910868,
     "sourceId": 116111,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
